{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pickle import dump, load\n",
    "import os\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classes: 7 - car | 15 - human"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1: data loader into separate trajectories for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_trajs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_datadir = '/nfs/diskstation/jren/projections/'\n",
    "for datadir in os.listdir(all_datadir):\n",
    "    pickled_path = os.path.join(all_datadir, datadir, 'trajectories.p')\n",
    "    if not os.path.exists(pickled_path):\n",
    "        continue\n",
    "    with open(pickled_path, 'r') as f:\n",
    "        datas = load(f)\n",
    "        for data in datas:\n",
    "            traj_type, traj_timed = data\n",
    "            if traj_type not in all_trajs:\n",
    "                all_trajs[traj_type] = []\n",
    "            traj = [val[0] for val in traj_timed]\n",
    "            all_trajs[traj_type].append(np.array(traj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/all_trajs_raw.p', 'w') as f:\n",
    "    dump(all_trajs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_trajs_zeroed = {}\n",
    "for key, trajs in all_trajs.items():\n",
    "    if key not in all_trajs_zeroed:\n",
    "        all_trajs_zeroed[key] = []\n",
    "    for traj in trajs:\n",
    "        traj_zero = traj[0]\n",
    "        all_trajs_zeroed[key].append(traj - traj_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/all_trajs_zeroed.p', 'w') as f:\n",
    "    dump(all_trajs_zeroed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_trajs_deltas = {}\n",
    "for key, trajs in all_trajs.items():\n",
    "    if key not in all_trajs_deltas:\n",
    "        all_trajs_deltas[key] = []\n",
    "    for traj in trajs:\n",
    "        traj_delta = traj[1:] - traj[:-1]\n",
    "        all_trajs_deltas[key].append(traj_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/all_trajs_deltas.p', 'w') as f:\n",
    "    dump(all_trajs_deltas, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: divide into train and test trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_test_ids = {}\n",
    "for key, val in all_trajs.items():\n",
    "    ids = np.arange(len(val))\n",
    "    np.random.shuffle(ids)\n",
    "    split = int(0.25 * len(ids))\n",
    "    train_test_ids[key] = {\n",
    "        'train': ids[split:], \n",
    "        'test': ids[:split]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/train_test_ids.p', 'w') as f:\n",
    "    dump(train_test_ids, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Processing Use Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_sets= {\n",
    "    'train':set(),\n",
    "    'test':set()\n",
    "}\n",
    "\n",
    "for path in os.listdir('ims/train'):\n",
    "    use_sets['train'].add(int(path[:-4]))\n",
    "    \n",
    "for path in os.listdir('ims/test'):\n",
    "    use_sets['test'].add(int(path[:-4]))\n",
    "    \n",
    "with open('data/use_sets.p', 'w') as f:\n",
    "    dump(use_sets, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Processing Street Im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "street_raw = imread('/nfs/diskstation/jren/projection_average.png')\n",
    "street = street_raw[97:719, 510:1132][:,:,:3]\n",
    "street = resize(street, [1000,1000])\n",
    "imsave('street.png', street)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
